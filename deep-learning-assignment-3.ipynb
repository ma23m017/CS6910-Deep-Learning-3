{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8212755,"sourceType":"datasetVersion","datasetId":4867367}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader \n\nfrom tqdm import tqdm\nimport heapq\nimport csv\n\nimport numpy as np\nimport random\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib.font_manager import FontProperties\n\nimport wandb\n# Instantiates the device to be used as GPU/CPU based on availability\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n#specify max length of sequence\nhin_embedd_size = 29\neng_embedd_size = 32\ndevice.type","metadata":{"execution":{"iopub.status.busy":"2024-05-16T12:46:07.374415Z","iopub.execute_input":"2024-05-16T12:46:07.375307Z","iopub.status.idle":"2024-05-16T12:46:07.387222Z","shell.execute_reply.started":"2024-05-16T12:46:07.375276Z","shell.execute_reply":"2024-05-16T12:46:07.386166Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}}]},{"cell_type":"code","source":"#ANOTHER STYLE BEGIN\n\nimport numpy as np\n\n# Load Data to capture all characters\narr = np.loadtxt(\"/kaggle/input/aksharantar-sampled2/aksharantar_sampled/hin/hin_train.csv\",\n                 delimiter=\",\", dtype=str)\nnum_sample = arr.shape[0]\nx_train, y_train = arr[:, 0], arr[:, 1]\n\nenglish_dict = {}\nhindi_dict = {}\nenglish_index_dict = {}\nhindi_index_dict = {}\n\n'''\nenglish_index = 3\nhin_index = 3'''\n\nenglish_index = hin_index = 3\n\nfor sentence in np.concatenate((x_train, y_train)):\n    for char in sentence:\n        if char not in english_dict:\n            english_dict[char] = english_index\n            english_index_dict[english_index] = char\n            english_index += 1\n\nfor sentence in y_train:\n    for char in sentence:\n        if char not in hindi_dict:\n            hindi_dict[char] = hin_index\n            hindi_index_dict[hin_index] = char\n            hin_index += 1\n\n# Adding start, stop and padding symbols\nstart_symbol = '<S>'\nend_symbol = '<E>'\npadding_symbol = '<P>'\nenglish_index_dict[0] = hindi_index_dict[0] = padding_symbol\nenglish_index_dict[1] = hindi_index_dict[1] = start_symbol\nenglish_index_dict[2] = hindi_index_dict[2] = end_symbol  #ANOTHER STYLE END\n","metadata":{"execution":{"iopub.status.busy":"2024-05-16T12:46:11.389259Z","iopub.execute_input":"2024-05-16T12:46:11.390181Z","iopub.status.idle":"2024-05-16T12:46:11.746073Z","shell.execute_reply.started":"2024-05-16T12:46:11.390141Z","shell.execute_reply":"2024-05-16T12:46:11.745251Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"#ANOTHER STYLE BEGIN\n\nimport numpy as np\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\n\nclass DataProcessor:\n    def __init__(self, eng_embedd_size, hin_embedd_size):\n        self.eng_embedd_size = eng_embedd_size\n        self.hin_embedd_size = hin_embedd_size\n        self.english_dict = {}\n        self.hindi_dict = {}\n\n    def process_data(self, path):\n        arr = np.loadtxt(path, delimiter=\",\", dtype=str)\n        num_samples = arr.shape[0]\n        x, y = arr[:, 0], arr[:, 1]\n\n        X = np.zeros((num_samples, self.eng_embedd_size))  # input\n        Y = np.zeros((num_samples, self.hin_embedd_size))  # target\n\n        for i in range(num_samples):\n            X[i][0] = Y[i][0] = 1\n\n            for j, char in enumerate(x[i]):\n                X[i][j + 1] = self.english_dict.setdefault(char, len(self.english_dict) + 3)\n\n            X[i][len(x[i]) + 1] = 2\n\n            for j, char in enumerate(y[i]):\n                Y[i][j + 1] = self.hindi_dict.setdefault(char, len(self.hindi_dict) + 3)\n\n            Y[i][len(y[i]) + 1] = 2\n\n        return X, Y\n\nclass CustomDataset(Dataset):\n    def __init__(self, X, Y):\n        self.X = torch.tensor(X, dtype=torch.int64)\n        self.Y = torch.tensor(Y, dtype=torch.int64)\n        self.length = X.shape[0]\n\n    def __getitem__(self, index):\n        return self.X[index], self.Y[index]\n\n    def __len__(self):\n        return self.length\n\ndata_processor = DataProcessor(eng_embedd_size, hin_embedd_size)\n\nX_train, y_train = data_processor.process_data(\"/kaggle/input/aksharantar-sampled2/aksharantar_sampled/hin/hin_train.csv\")\nX_val, y_val = data_processor.process_data(\"/kaggle/input/aksharantar-sampled2/aksharantar_sampled/hin/hin_valid.csv\")\nX_test, y_test = data_processor.process_data(\"/kaggle/input/aksharantar-sampled2/aksharantar_sampled/hin/hin_test.csv\")\n\ntrain_dataset = CustomDataset(X_train, y_train)\nval_dataset = CustomDataset(X_val, y_val)\ntest_dataset = CustomDataset(X_test, y_test)\n\ntrain_loader = DataLoader(train_dataset, shuffle=True, batch_size=256)\nval_loader = DataLoader(val_dataset, shuffle=True, batch_size=256)\ntest_loader = DataLoader(test_dataset, shuffle=False, batch_size=256) #ANOTHER STYLE END","metadata":{"execution":{"iopub.status.busy":"2024-05-16T12:46:14.982855Z","iopub.execute_input":"2024-05-16T12:46:14.983789Z","iopub.status.idle":"2024-05-16T12:46:16.232807Z","shell.execute_reply.started":"2024-05-16T12:46:14.983745Z","shell.execute_reply":"2024-05-16T12:46:16.231874Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"#  ANOTHER STYLE BEGIN\nimport torch\nimport torch.nn as nn\n\nclass Encoder(nn.Module):\n    \n    def __init__(self,\n                 input_dimension=72,\n                 embed_dimension=64,\n                 hidden_dimension=256,\n                 cell_type='gru',\n                 layers=2,\n                 bidirectional=True,\n                 dropout=0,\n                 device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n                ):\n        super(Encoder, self).__init__()\n        \n        self.detail_parameters = {}\n        self.detail_parameters['input_dimension'] = input_dimension\n        self.detail_parameters['embed_dimension'] = embed_dimension\n        self.detail_parameters['hidden_dimension'] = hidden_dimension\n        self.detail_parameters['cell_type'] = cell_type\n        self.detail_parameters['dropout'] = dropout\n        self.detail_parameters['layers'] = layers\n        self.detail_parameters['direction_value'] = 2 if bidirectional else 1\n        self.detail_parameters['device'] = device.type\n\n        \n        self.input_dimension = input_dimension\n        self.embed_dimension = embed_dimension\n        self.hidden_dimension = hidden_dimension\n        self.cell_type = cell_type\n        self.layers = layers\n        self.dropout = dropout\n        self.device = device\n\n        self.embedding = nn.Embedding(self.input_dimension, self.embed_dimension)\n        self.dropout_layer = nn.Dropout(dropout)\n        \n        self.direction_value = 2 if bidirectional else 1\n\n        # Define different types of recurrent cells\n        if self.cell_type == 'rnn':\n            self.encoder_type = RNNLayer(self.embed_dimension, self.hidden_dimension, self.layers, bidirectional, dropout)\n        elif self.cell_type == 'gru':\n            self.encoder_type = GRULayer(self.embed_dimension, self.hidden_dimension, self.layers, bidirectional, dropout)\n        elif self.cell_type == 'lstm':\n            self.encoder_type = LSTMLayer(self.embed_dimension, self.hidden_dimension, self.layers, bidirectional, dropout)\n\n    def forward(self, input, hidden, cell=None):\n        embedded = self.embedding(input)\n        embedded = self.dropout_layer(embedded)\n        \n        if self.cell_type == 'lstm':\n            output, (hidden, cell) = self.encoder_type(embedded, (hidden, cell))\n        else:\n            output, hidden = self.encoder_type(embedded, hidden)\n\n        return output, hidden, cell if self.cell_type == 'lstm' else None\n\n    def getParams(self):\n        return self.detail_parameters\n    \n    def init_hidden(self, batch):\n        return torch.zeros(self.direction_value * self.layers, batch, self.hidden_dimension, device=self.device)\n\n# Define RNN layer as a subclass of nn.Module\nclass RNNLayer(nn.Module):\n    def __init__(self, input_size, hidden_size, num_layers, bidirectional, dropout):\n        super(RNNLayer, self).__init__()\n        self.rnn = nn.RNN(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, bidirectional=bidirectional, dropout=dropout)\n\n    def forward(self, input, hidden):\n        return self.rnn(input, hidden)\n\n# Define GRU layer as a subclass of nn.Module\nclass GRULayer(nn.Module):\n    def __init__(self, input_size, hidden_size, num_layers, bidirectional, dropout):\n        super(GRULayer, self).__init__()\n        self.gru = nn.GRU(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, bidirectional=bidirectional, dropout=dropout)\n\n    def forward(self, input, hidden):\n        return self.gru(input, hidden)\n\n# Define LSTM layer as a subclass of nn.Module\nclass LSTMLayer(nn.Module):\n    def __init__(self, input_size, hidden_size, num_layers, bidirectional, dropout):\n        super(LSTMLayer, self).__init__()\n        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, bidirectional=bidirectional, dropout=dropout)\n\n    def forward(self, input, hidden):\n        return self.lstm(input, hidden)  #ANOTHER STYLE END\n","metadata":{"execution":{"iopub.status.busy":"2024-05-16T12:46:20.299982Z","iopub.execute_input":"2024-05-16T12:46:20.300659Z","iopub.status.idle":"2024-05-16T12:46:20.319313Z","shell.execute_reply.started":"2024-05-16T12:46:20.300631Z","shell.execute_reply":"2024-05-16T12:46:20.318493Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Decoder(nn.Module):\n    def __init__(self,\n                 input_dimension=26,\n                 embed_dimension=64,\n                 hidden_dimension=256,\n                 cell_type='lstm',\n                 layers=2,\n                 use_attention=False,\n                 attention_dimension=None,\n                 dropout=0,\n                 bidirectional=True,\n                 device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n                ):\n        super(Decoder, self).__init__()\n\n        self.input_dimension = input_dimension\n        self.embed_dimension = embed_dimension\n        self.hidden_dimension = hidden_dimension\n        self.cell_type = cell_type\n        self.layers = layers\n        self.use_attention = use_attention\n        self.attention_dimension = attention_dimension\n        self.dropout = dropout\n        self.device = device\n        #self.linear_transform = nn.Linear(hidden_dimension, output_dimension)  # Adjust output_dimension as needed\n\n        # Embedding layer\n        self.embedding = nn.Embedding(input_dimension, embed_dimension)\n        self.dropout_layer = nn.Dropout(dropout)\n\n        # Calculate input size considering attention\n        self.input_size = embed_dimension\n        if use_attention:\n            self.input_size += attention_dimension\n\n        # Define decoder type (RNN, GRU, LSTM)\n        if cell_type == 'rnn':\n            self.decoder_type = nn.RNN(input_size=self.input_size, hidden_size=hidden_dimension,\n                                        num_layers=layers, bidirectional=bidirectional, dropout=dropout)\n        elif cell_type == 'gru':\n            self.decoder_type = nn.GRU(input_size=self.input_size, hidden_size=hidden_dimension,\n                                        num_layers=layers, bidirectional=bidirectional, dropout=dropout)\n        elif cell_type == 'lstm':\n            self.decoder_type = nn.LSTM(input_size=self.input_size, hidden_size=hidden_dimension,\n                                         num_layers=layers, bidirectional=bidirectional, dropout=dropout)\n\n        # Attention mechanism components\n        if use_attention:\n            self.U = nn.Linear(hidden_dimension, hidden_dimension)\n            self.W = nn.Linear(hidden_dimension, hidden_dimension)\n            self.V = nn.Linear(hidden_dimension, 1)\n\n        # Output layer to match input dimension\n        self.W1 = nn.Linear(hidden_dimension * (2 if bidirectional else 1), input_dimension)\n    \n    def forward(self, input, hidden, cell=None, encoder_outputs=None):\n        embedded = self.embedding(input)\n        embedded = self.dropout_layer(embedded)\n\n        # Apply attention mechanism if enabled\n        if self.use_attention:\n            context, attention_weights = self.apply_attention(hidden, encoder_outputs)\n            embedded = torch.cat((embedded, context), 2)\n\n        # Pass through decoder RNN type\n        if self.cell_type == 'lstm':\n            output, (hidden, cell) = self.decoder_type(embedded, (hidden, cell))\n        else:\n            output, hidden = self.decoder_type(embedded, hidden)\n\n        # Apply linear layer to match output dimension\n        output = self.W1(output)\n\n        return output, hidden, cell, attention_weights if self.use_attention else None\n    \n\n    \n    def apply_attention(self, hidden, encoder_outputs):\n    # Project encoder outputs and hidden state\n        encoder_transform = self.W(encoder_outputs)\n        hidden_transform = self.U(hidden)\n\n    # Combine encoder and hidden transformations\n        concat_transform = encoder_transform + hidden_transform\n\n    # Apply activation function\n        concat_transform = torch.tanh(concat_transform)\n\n    # Calculate attention scores\n        score = self.V(concat_transform)\n\n    # Apply softmax to get attention weights\n        attention_weights = F.softmax(score, dim=1)\n\n    # Compute context vector\n        context_vector = torch.sum(attention_weights * encoder_outputs, dim=1)\n\n    # Reshape context vector\n        normalized_context_vector = context_vector.unsqueeze(0)\n\n        return normalized_context_vector, attention_weights\n\n    \n    def getParams(self):\n        return {\n            'input_dimension': self.input_dimension,\n            'embed_dimension': self.embed_dimension,\n            'hidden_dimension': self.hidden_dimension,\n            'attention_dimension': self.attention_dimension,\n            'cell_type': self.cell_type,\n            'layers': self.layers,\n            'device': self.device.type,\n            'dropout': self.dropout,\n            'use_attention': self.use_attention,\n            'attention_dimension': self.attention_dimension\n        }","metadata":{"execution":{"iopub.status.busy":"2024-05-16T12:46:23.718430Z","iopub.execute_input":"2024-05-16T12:46:23.719318Z","iopub.status.idle":"2024-05-16T12:46:23.737952Z","shell.execute_reply.started":"2024-05-16T12:46:23.719284Z","shell.execute_reply":"2024-05-16T12:46:23.736927Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"import torch\nimport heapq\n\nclass BeamNode:\n    def __init__(self, index, path_probability, hidden_state, cell_state, parent=None):\n        self.index = index\n        self.path_probability = path_probability\n        self.hidden_state = hidden_state\n        self.cell_state = cell_state\n        self.parent = parent\n        self.length = 0\n\ndef expand_node(model, node):\n    output, dec_hidden, cell, _ = model.decoder.forward(node.index, node.hidden, node.cell, None)\n    output = model.softmax(output, dim=2)\n    topk_output, topk_index = torch.topk(output, model.beam_width, dim=2)\n    return topk_output, topk_index, dec_hidden, cell\n\ndef create_child_nodes(model, topk_output, topk_index, dec_hidden, cell, curr_node):\n    child_nodes = []\n    for j in range(model.beam_width):\n        output = topk_output[:, :, j]\n        index = topk_index[:, :, j]\n        if curr_node.path_probability * output.item() < 0.001:\n            continue\n        child_node = BeamNode(output.item(), curr_node.path_probability * output.item(), index, dec_hidden, cell, curr_node)\n        child_node.length = curr_node.length + 1\n        child_nodes.append(child_node)\n    return child_nodes\n\ndef traverse_path(model, path, predicted):\n    while path is not None:\n        output, _, _, _ = model.decoder.forward(path.index, path.hidden, path.cell, None)\n        predicted[model.output_seq_length - path.length, i:i+1] = output\n        path = path.parent\n\ndef beam_search(model, outputs, dec_hiddens, cells, predicted):\n    batch_size = outputs.shape[1]\n    paths = []\n\n    for i in range(batch_size):\n        with torch.no_grad():\n            model.eval()\n            output = outputs[:, i:i+1].contiguous()\n            index = output.contiguous()\n            dec_hidden = dec_hiddens[:, i:i+1, :].contiguous()\n            cell = cells[:, i:i+1, :].contiguous() if cells is not None else None\n            \n            open_list = []\n            heapq.heapify(open_list)\n            \n            root_node = BeamNode(1, 1, index, dec_hidden, cell, None)\n            heapq.heappush(open_list, root_node)\n\n            while len(open_list) > 0:\n                curr_node = heapq.heappop(open_list)\n                \n                if curr_node.length == model.output_seq_length - 1:\n                    paths.append(curr_node)\n                    continue\n\n                topk_output, topk_index, dec_hidden, cell = expand_node(model, curr_node)\n                child_nodes = create_child_nodes(model, topk_output, topk_index, dec_hidden, cell, curr_node)\n                for node in child_nodes:\n                    heapq.heappush(open_list, node)\n\n            if len(paths) > 0:\n                best_path = min(paths, key=lambda x: x.path_probability)\n                traverse_path(model, best_path, predicted)\n            else:\n                for t in range(1, model.output_seq_length):\n                    output, _, _, _ = model.decoder.forward(index, dec_hidden, cell, None)\n                    predicted[t, i:i+1] = output\n                    output = model.softmax(output, dim=2)\n                    output = torch.argmax(output, dim=2)","metadata":{"execution":{"iopub.status.busy":"2024-05-16T12:47:36.138120Z","iopub.execute_input":"2024-05-16T12:47:36.138473Z","iopub.status.idle":"2024-05-16T12:47:36.156700Z","shell.execute_reply.started":"2024-05-16T12:47:36.138435Z","shell.execute_reply":"2024-05-16T12:47:36.155655Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}