{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8212755,"sourceType":"datasetVersion","datasetId":4867367}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\n'''\ndef create_vocab(text):\n    vocab = set(char for word in text for char in word)\n    vocab.add('<pad>')\n    vocab.add('<sos>') #start of sequence\n    vocab.add('<eos>') #end of sequence\n    return vocab'''\ndef create_vocab(text):\n    return set().union(*map(set, text)) | {'<pad>', '<sos>', '<eos>'}\n\n\ndef load_data(path):\n    df = pd.read_csv(path, header = None, names = ['latin','devanagari'])\n    return df['latin'], df['devanagari']\n\nlatin_train, devanagari_train = load_data('/kaggle/input/aksharantar-sampled2/aksharantar_sampled/hin/hin_train.csv')\nlatin_valid, devanagari_valid = load_data('/kaggle/input/aksharantar-sampled2/aksharantar_sampled/hin/hin_valid.csv')\nlatin_test, devanagari_test = load_data('/kaggle/input/aksharantar-sampled2/aksharantar_sampled/hin/hin_test.csv')\n\n#print(latin_train, devanagari_train, end='\\n')\n\nlatin_vocab = create_vocab(latin_train)\nprint(latin_vocab)\n\ndevanagari_vocab = create_vocab(devanagari_train)\n#print(devanagari_vocab)\n\nlatin_token2idx = {token:idx for idx, token in enumerate(sorted(latin_vocab))}\n#print(latin_token2idx)\n\ndevanagari_token2idx = {token:idx for idx, token in enumerate(sorted(devanagari_vocab))}\n#print(devanagari_token2idx)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-03T08:08:09.953570Z","iopub.execute_input":"2024-05-03T08:08:09.954373Z","iopub.status.idle":"2024-05-03T08:08:14.818691Z","shell.execute_reply.started":"2024-05-03T08:08:09.954323Z","shell.execute_reply":"2024-05-03T08:08:14.817746Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"{'s', 'p', 'r', 'n', 'e', 'a', 'v', 'i', 'z', 'u', 'm', '<pad>', 'b', 'q', 'y', 'f', 'w', 'd', 'l', '<eos>', 'c', 't', 'o', 'g', '<sos>', 'k', 'j', 'x', 'h'}\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\n'''\nclass AksharantarDataset(Dataset):\n    def __init__(self, latin_words, devanagari_words, latin_token2idx, devanagari_token2idx):\n        self.latin_words = latin_words\n        self.devanagari_words = devanagari_words\n        self.latin_token2idx = latin_token2idx\n        self.devanagari_token2idx = devanagari_token2idx\n\n        # Determine the index for the '<unk>' token\n        self.unk_idx = max(devanagari_token2idx.values()) + 1\n\n    def __len__(self):\n        return len(self.latin_words)\n\n    def __getitem__(self, idx):\n        latin_word = self.latin_words.iloc[idx]\n        devanagari_word = self.devanagari_words.iloc[idx]\n\n        # Convert Latin word to indices\n        latin_indices = [latin_token2idx[char] for char in latin_word]\n\n        # Convert Devanagari word to indices\n        devanagari_indices = []\n        for char in devanagari_word:\n            # Handle characters not present in devanagari_token2idx\n            if char in devanagari_token2idx:\n                devanagari_indices.append(devanagari_token2idx[char])\n            else:\n                devanagari_indices.append(self.unk_idx)  # Assign '<unk>' token index\n\n        # Add <sos> and <eos> tokens\n        devanagari_indices = [devanagari_token2idx['<sos>']] + devanagari_indices + [devanagari_token2idx['<eos>']]\n\n        return torch.tensor(latin_indices, dtype=torch.long), torch.tensor(devanagari_indices, dtype=torch.long)'''\n\nclass AksharantarDataset(Dataset):\n    def __init__(self, latin_words, devanagari_words, latin_token2idx, devanagari_token2idx):\n        self.latin_words = latin_words\n        self.devanagari_words = devanagari_words\n        self.latin_token2idx = latin_token2idx\n        self.devanagari_token2idx = devanagari_token2idx\n\n        # Determine the index for the '<unk>' token\n        self.unk_idx = max(devanagari_token2idx.values(), default=-1) + 1\n\n    def __len__(self):\n        return len(self.latin_words)\n\n    def __getitem__(self, idx):\n        latin_indices = [self.latin_token2idx.get(char, self.unk_idx) for char in self.latin_words.iloc[idx]]\n        devanagari_indices = [self.devanagari_token2idx.get(char, self.unk_idx) for char in self.devanagari_words.iloc[idx]]\n\n        # Add <sos> and <eos> tokens\n        devanagari_indices = list(map(self.devanagari_token2idx.get, ['<sos>'])) + devanagari_indices + list(map(self.devanagari_token2idx.get, ['<eos>']))\n\n        return torch.tensor(latin_indices, dtype=torch.long), torch.tensor(devanagari_indices, dtype=torch.long)\n\n\n''' \ndef collate_fn(batch):\n    latin, devanagari = zip(*batch)  # Unpack batch\n    latin_padded = pad_sequence(latin, batch_first=True, padding_value=latin_token2idx['<pad>'])\n    devanagari_padded = pad_sequence(devanagari, batch_first=True, padding_value=devanagari_token2idx['<pad>'])\n    return latin_padded, devanagari_padded'''\n\ndef collate_fn(batch):\n    # Unpack batch and pad sequences\n    latin_padded = pad_sequence([torch.tensor(latin_seq) for latin_seq, _ in batch], batch_first=True, padding_value=latin_token2idx['<pad>'])\n    devanagari_padded = pad_sequence([torch.tensor(devanagari_seq) for _, devanagari_seq in batch], batch_first=True, padding_value=devanagari_token2idx['<pad>'])\n    return latin_padded, devanagari_padded\n\n    \ntrain_dataset = AksharantarDataset(latin_train, devanagari_train, latin_token2idx, devanagari_token2idx)\ntrain_loader = DataLoader(train_dataset, batch_size = 32, collate_fn = collate_fn, shuffle=True)\n\nvalid_dataset = AksharantarDataset(latin_valid, devanagari_valid, latin_token2idx, devanagari_token2idx)\nvalid_loader = DataLoader(valid_dataset, batch_size = 32, collate_fn = collate_fn, shuffle=True)\n\ntest_dataset = AksharantarDataset(latin_test, devanagari_test, latin_token2idx, devanagari_token2idx)\ntest_loader = DataLoader(test_dataset, batch_size=1, collate_fn = collate_fn, shuffle=False)\n\nprint(train_dataset[5869])","metadata":{"execution":{"iopub.status.busy":"2024-05-03T08:08:34.340147Z","iopub.execute_input":"2024-05-03T08:08:34.340516Z","iopub.status.idle":"2024-05-03T08:08:34.387312Z","shell.execute_reply.started":"2024-05-03T08:08:34.340486Z","shell.execute_reply":"2024-05-03T08:08:34.386256Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"(tensor([18,  3, 18,  3, 13, 23, 20,  3]), tensor([ 2, 38, 54, 38, 54, 18, 57, 44, 54,  0]))\n","output_type":"stream"}]},{"cell_type":"code","source":"'''\nclass Encoder(nn.Module):\n    def __init__(self, input_size, embedding_size, hidden_size, num_layers, rnn_cell = 'lstm', dropout = 0.5):\n        super(Encoder, self).__init__()\n        self.embedding = nn.Embedding(num_embeddings = input_size, embedding_dim = embedding_size)\n        self.dropout = nn.Dropout(dropout)\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        \n        if rnn_cell.lower() == 'lstm':\n            self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, batch_first = True, dropout = dropout)\n        elif rnn_cell.lower == 'gru':\n            self.rnn = nn.GRU(embedding_size, hidden_size, num_layers, batch_first = True, dropout = dropout)\n        else:\n            self.rnn = nn.RNN(embedding_size, hidden_size, num_layers, batch_first = True, dropout = dropout)\n            \n    def forward(self,x):\n        embedded = self.dropout(self.embedding(x))\n        outputs, hidden = self.rnn(embedded)\n        return hidden'''\n\nclass Encoder(nn.Module):\n    def __init__(self, input_size, embedding_size, hidden_size, num_layers, rnn_cell='lstm', dropout=0.5):\n        super().__init__()\n        \n        self.embedding = nn.Embedding(input_size, embedding_size)\n        self.rnn_cell = rnn_cell.lower()\n        \n        rnn_class = getattr(nn, self.rnn_cell.upper())\n        self.rnn = rnn_class(embedding_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n        \n        self.dropout = nn.Dropout(dropout)\n        \n    def forward(self, x):\n        embedded = self.dropout(self.embedding(x))\n        outputs, hidden = self.rnn(embedded)\n        return hidden","metadata":{"execution":{"iopub.status.busy":"2024-05-03T08:09:04.052686Z","iopub.execute_input":"2024-05-03T08:09:04.053655Z","iopub.status.idle":"2024-05-03T08:09:04.062268Z","shell.execute_reply.started":"2024-05-03T08:09:04.053615Z","shell.execute_reply":"2024-05-03T08:09:04.061329Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"'''\nclass Decoder(nn.Module):\n    def __init__(self, output_size, embedding_size, hidden_size, num_layers, rnn_cell = 'lstm', dropout = 0.5):\n        super(Decoder, self).__init__()\n        self.embedding = nn.Embedding(num_embeddings = output_size, embedding_dim = embedding_size)\n        self.dropout = nn.Dropout(dropout)\n        self.output_size = output_size\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        \n        if rnn_cell.lower() == 'lstm':\n            self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, batch_first = True, dropout = dropout)\n        elif rnn_cell.lower == 'gru':\n            self.rnn = nn.GRU(embedding_size, hidden_size, num_layers, batch_first = True, dropout = dropout)\n        else:\n            self.rnn = nn.RNN(embedding_size, hidden_size, num_layers, batch_first = True, dropout = dropout)\n            \n        self.fc = nn.Linear(hidden_size, output_size)\n            \n    def forward(self,x, hidden):\n        x = x.unsqueeze(1)\n        embedded = self.dropout(self.embedding(x))\n        output, hidden = self.rnn(embedded, hidden)\n        prediction = self.fc(self.dropout(output.squeeze(1)))\n        return prediction, hidden'''\n\nclass Decoder(nn.Module):\n    def __init__(self, output_size, embedding_size, hidden_size, num_layers, rnn_cell='lstm', dropout=0.5):\n        super().__init__()\n\n        self.embedding = nn.Embedding(output_size, embedding_size)\n        self.dropout = nn.Dropout(dropout)\n        self.output_size = output_size\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n\n        rnn_cell = rnn_cell.lower()\n        rnn_class = getattr(nn, rnn_cell.upper())\n        self.rnn = rnn_class(embedding_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n            \n        self.fc = nn.Linear(hidden_size, output_size)\n            \n    def forward(self, x, hidden=None):\n        if hidden is None:\n            hidden = self.init_hidden(x.size(0))\n            \n        embedded = self.dropout(self.embedding(x.unsqueeze(1)))\n        output, hidden = self.rnn(embedded, hidden)\n        prediction = self.fc(self.dropout(output.squeeze(1)))\n        return prediction, hidden\n    \n    def init_hidden(self, batch_size):\n        weight = next(self.parameters()).data\n        if isinstance(self.rnn, nn.LSTM):\n            return (weight.new(self.num_layers, batch_size, self.hidden_size).zero_(),\n                    weight.new(self.num_layers, batch_size, self.hidden_size).zero_())\n        else:\n            return weight.new(self.num_layers, batch_size, self.hidden_size).zero_()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-03T08:09:26.344538Z","iopub.execute_input":"2024-05-03T08:09:26.345207Z","iopub.status.idle":"2024-05-03T08:09:26.356772Z","shell.execute_reply.started":"2024-05-03T08:09:26.345173Z","shell.execute_reply":"2024-05-03T08:09:26.355699Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"'''\nclass seq2seq(nn.Module):\n    def __init__(self, encoder, decoder):\n        super(seq2seq, self).__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n        \n    def forward(self, source, target, teaching_force_ratio=0.5):\n        batch_size = source.size(0)\n        target_len = target.size(1)\n        target_vocab_size = self.decoder.output_size\n        \n        outputs = torch.zeros(batch_size, target_len, target_vocab_size).to(source.device)\n        \n        encoder_hidden = self.encoder(source)\n        decoder_input = target[:,0]\n        \n        for t in range(1, target_len):\n            decoder_output, encoder_hidden = self.decoder(decoder_input, encoder_hidden)\n            outputs[:,t] = decoder_output\n            teacher_force = torch.rand(1)<teaching_force_ratio\n            top1 = decoder_output.argmax(1)\n            decoder_input = target[:, t] if teacher_force else top1\n            \n        return outputs'''\n\nclass Seq2Seq(nn.Module):\n    def __init__(self, encoder, decoder):\n        super().__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n        \n    def forward(self, source, target, teaching_force_ratio=0.5):\n        batch_size, target_len = target.size()\n        target_vocab_size = self.decoder.output_size\n        \n        outputs = torch.zeros(batch_size, target_len, target_vocab_size, device=source.device)\n        \n        encoder_hidden = self.encoder(source)\n        decoder_input = target[:, 0]\n        \n        for t in range(1, target_len):\n            decoder_output, encoder_hidden = self.decoder(decoder_input, encoder_hidden)\n            outputs[:, t] = decoder_output\n            teacher_force = (t / target_len) < teaching_force_ratio\n            decoder_input = target[:, t] if teacher_force else decoder_output.argmax(dim=1)\n            \n        return outputs\n","metadata":{"execution":{"iopub.status.busy":"2024-05-03T08:09:32.998377Z","iopub.execute_input":"2024-05-03T08:09:32.999222Z","iopub.status.idle":"2024-05-03T08:09:33.011771Z","shell.execute_reply.started":"2024-05-03T08:09:32.999181Z","shell.execute_reply":"2024-05-03T08:09:33.010685Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"input_dim = 256\noutput_dim = 256\nenc_emb_dim = 64\ndec_emb_dim = 64\nhidden_dim = 512\nenc_layers = 2\ndec_layers = 2\nenc_rnn_cell = 'lstm'\ndec_rnn_cell = 'lstm'\n\nencoder = Encoder(input_dim, enc_emb_dim, hidden_dim, enc_layers, enc_rnn_cell)\ndecoder = Decoder(output_dim, dec_emb_dim, hidden_dim, dec_layers, dec_rnn_cell)\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device)\n\nmodel = Seq2Seq(encoder, decoder).to(device)\nprint(model)","metadata":{"execution":{"iopub.status.busy":"2024-05-03T08:09:44.437573Z","iopub.execute_input":"2024-05-03T08:09:44.437935Z","iopub.status.idle":"2024-05-03T08:09:44.818474Z","shell.execute_reply.started":"2024-05-03T08:09:44.437905Z","shell.execute_reply":"2024-05-03T08:09:44.817558Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"cuda\nSeq2Seq(\n  (encoder): Encoder(\n    (embedding): Embedding(256, 64)\n    (rnn): LSTM(64, 512, num_layers=2, batch_first=True, dropout=0.5)\n    (dropout): Dropout(p=0.5, inplace=False)\n  )\n  (decoder): Decoder(\n    (embedding): Embedding(256, 64)\n    (dropout): Dropout(p=0.5, inplace=False)\n    (rnn): LSTM(64, 512, num_layers=2, batch_first=True, dropout=0.5)\n    (fc): Linear(in_features=512, out_features=256, bias=True)\n  )\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"'''\ndef categorical_accuracy(preds, y, ignore_index):\n    max_preds = preds.argmax(dim=1, keepdim=True)\n    non_pad_elements = (y != ignore_index).nonzero()\n    correct = max_preds[non_pad_elements].squeeze(1).eq(y[non_pad_elements])\n    return correct.sum()/torch.FloatTensor([y[non_pad_elements].shape[0]]).to(y.device)'''\n\ndef categorical_accuracy(preds, y, ignore_index):\n    mask = y != ignore_index\n    correct = preds.argmax(dim=1).eq(y)\n    correct_masked = correct[mask]\n    return correct_masked.sum().float() / mask.sum().float()\n\n\ndef train(model, iterator, optimizer, criterion, clip, device, ignore_index):\n    model.train()\n    epoch_loss = 0\n    epoch_accuracy = 0\n    \n    for source, target in iterator:\n        source = source.to(device)\n        target = target.to(device)\n        \n        optimizer.zero_grad()\n        output = model(source, target)\n        \n        output_dim = output.shape[-1]\n        output = output[:,1:].reshape(-1, output_dim)\n        target = target[:, 1:].reshape(-1)\n        \n        loss = criterion(output, target)\n        accuracy = categorical_accuracy(output, target, ignore_index)\n        \n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n        optimizer.step()\n        \n        epoch_loss += loss.item()\n        epoch_accuracy += accuracy.item()\n        \n    return epoch_loss/len(iterator), epoch_accuracy/len(iterator)\n\ndef evaluate(model, iterator, criterion, device, ignore_index):\n    model.eval()\n    epoch_loss = 0\n    epoch_accuracy = 0\n    \n    with torch.no_grad():\n        for source, target in iterator:\n            source = source.to(device)\n            target = target.to(device)\n            \n            output = model(source, target, 0)\n            output_dim = output.shape[-1]\n            output = output[:, 1:].reshape(-1, output_dim)\n            target = target[:, 1:].reshape(-1)\n            \n            loss = criterion(output, target)\n            accuracy = categorical_accuracy(output, target, ignore_index)\n            \n            epoch_loss += loss.item()\n            epoch_accuracy += accuracy.item()\n            \n    return epoch_loss/len(iterator), epoch_accuracy/len(iterator)","metadata":{"execution":{"iopub.status.busy":"2024-05-03T08:09:52.792612Z","iopub.execute_input":"2024-05-03T08:09:52.793479Z","iopub.status.idle":"2024-05-03T08:09:52.806187Z","shell.execute_reply.started":"2024-05-03T08:09:52.793444Z","shell.execute_reply":"2024-05-03T08:09:52.805164Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from torch.nn.utils.rnn import pad_sequence\nnum_epoch = 10\nclip = 1\noptimizer = torch.optim.Adam(model.parameters())\nignore_index = devanagari_token2idx['<pad>']\ncriterion = nn.CrossEntropyLoss(ignore_index = ignore_index).to(device)\n\nfor epoch in range(num_epoch):\n    train_loss, train_accuracy = train(model, train_loader, optimizer, criterion, clip, device, ignore_index)\n    valid_loss, valid_accuracy = evaluate(model, valid_loader, criterion, device, ignore_index)\n    \n    print(f'Epoch:{epoch+1}')\n    print(f'Train Loss: {train_loss:.2f} | Train Accuracy: {train_accuracy:.2f}')\n    print(f'Validation Loss: {valid_loss:.2f} | Validation Accuracy: {valid_accuracy:.2f}')","metadata":{"execution":{"iopub.status.busy":"2024-05-03T08:15:20.475640Z","iopub.execute_input":"2024-05-03T08:15:20.476288Z","iopub.status.idle":"2024-05-03T08:19:09.273437Z","shell.execute_reply.started":"2024-05-03T08:15:20.476254Z","shell.execute_reply":"2024-05-03T08:19:09.272233Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_36/2162778521.py:70: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  latin_padded = pad_sequence([torch.tensor(latin_seq) for latin_seq, _ in batch], batch_first=True, padding_value=latin_token2idx['<pad>'])\n/tmp/ipykernel_36/2162778521.py:71: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  devanagari_padded = pad_sequence([torch.tensor(devanagari_seq) for _, devanagari_seq in batch], batch_first=True, padding_value=devanagari_token2idx['<pad>'])\n","output_type":"stream"},{"name":"stdout","text":"Epoch:1\nTrain Loss: 2.69 | Train Accuracy: 0.28\nValidation Loss: 2.59 | Validation Accuracy: 0.40\nEpoch:2\nTrain Loss: 1.43 | Train Accuracy: 0.59\nValidation Loss: 1.74 | Validation Accuracy: 0.62\nEpoch:3\nTrain Loss: 0.92 | Train Accuracy: 0.71\nValidation Loss: 1.64 | Validation Accuracy: 0.67\nEpoch:4\nTrain Loss: 0.76 | Train Accuracy: 0.76\nValidation Loss: 1.65 | Validation Accuracy: 0.69\nEpoch:5\nTrain Loss: 0.67 | Train Accuracy: 0.78\nValidation Loss: 1.64 | Validation Accuracy: 0.70\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[8], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss(ignore_index \u001b[38;5;241m=\u001b[39m ignore_index)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epoch):\n\u001b[0;32m----> 9\u001b[0m     train_loss, train_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclip\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     valid_loss, valid_accuracy \u001b[38;5;241m=\u001b[39m evaluate(model, valid_loader, criterion, device, ignore_index)\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n","Cell \u001b[0;32mIn[7], line 34\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion, clip, device, ignore_index)\u001b[0m\n\u001b[1;32m     31\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, target)\n\u001b[1;32m     32\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m categorical_accuracy(output, target, ignore_index)\n\u001b[0;32m---> 34\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), clip)\n\u001b[1;32m     36\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}