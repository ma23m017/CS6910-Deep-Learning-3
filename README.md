# CS6910-Deep-Learning-3

## Overview:

In this assignment I have made a model sequence2sequence learning problems using Reccurent Neural Networks. Then I also have compared different cells such as RNN, LSTM and GRU. I also worked with attention and understood the working and also observed that attention netwroks generally overcomes effeciently the limitations of vanilla sequence2sequence models. For this assignment I have used Aksharantar Dataset which contains a word in native script and it's corresponding transliteration in the Latin script. I have used Python for my implementation and have used the required packages from PyTorch and also used several required libraries. I ran my code on kaggle.
